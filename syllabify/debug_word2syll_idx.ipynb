{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import itertools\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = np.load('../data/train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "qw_idxs = torch.load('../data_dev/qw_idxs.pt') # torch.Size([64, 29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 29])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size, len, \n",
    "qw_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2200]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/word_idx2syll_idx.json') as json_file:  \n",
    "    word_idx2syll_idx = json.load(json_file)\n",
    "word_idx2syll_idx['534']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/syll2idx.json') as json_file:  \n",
    "    syll2idx = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 29])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_len = max(len(sent) for sent in qw_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   191,   534,  ...,     0,     0,     0],\n",
       "        [    1,   191,    12,  ...,     0,     0,     0],\n",
       "        [    1,    24, 51294,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    1,   999,  2150,  ...,     0,     0,     0],\n",
       "        [    1,  2461,  4003,  ...,     0,     0,     0],\n",
       "        [    1,   999,  1172,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8,  7, 11, 15, 11, 13,  9,  9,  9, 13, 14, 10, 18,  6, 11, 13,  8,  8,\n",
       "        11, 19, 11, 16, 13, 12, 12, 10,  9,  8, 13, 14, 16, 10, 17, 29, 11, 13,\n",
       "        12, 20, 10,  6, 18,  7, 12,  7, 10, 17, 16, 10, 19, 11, 14, 10,  9, 13,\n",
       "        15,  9, 14, 15, 16, 13, 13, 14, 12,  7])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_mask = torch.zeros_like(qw_idxs) != qw_idxs\n",
    "q_len = q_mask.sum(-1)\n",
    "q_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 29, 6])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def word2syll_idxs(w_idxs, word_idx2syll_idx, pad_idx=0, unk_idx=1):\n",
    "    \"\"\"\n",
    "    Convert a list tensor of word indices to syllable indices.\n",
    "    @param w_idxs (Tensor): batch of word indices (context or question)\n",
    "    @param word_idx2syll_idx (Dict[str->list[int]]): mapping vocabulary index to syllable index\n",
    "    @param unk_idx (int): index to padding token (0)\n",
    "    \"\"\"\n",
    "    \n",
    "    syll_idxs = []\n",
    "    max_word_len = 0\n",
    "    for sent in w_idxs:\n",
    "        syll_idx = [word_idx2syll_idx[str(i)] if str(i) in word_idx2syll_idx else [pad_idx] if str(i) == '0' else [unk_idx] for i in sent.tolist()]\n",
    "        syll_idxs.append(syll_idx)\n",
    "        max_tmp = max(len(idxs) for idxs in syll_idx)\n",
    "        max_word_len = max(max_word_len, max_tmp)\n",
    "    \n",
    "    # pad word to max word length (measured in syllables)\n",
    "    for i, sent in enumerate(syll_idxs):\n",
    "        for j, word in enumerate(sent):\n",
    "            syll_idxs[i][j] += [pad_idx] * (max_word_len - len(word))\n",
    "    \n",
    "    # pad sentence to max sentence length (measured in words)\n",
    "    max_sen_len = max(len(sent) for sent in syll_idxs)\n",
    "    for i, sent in enumerate(syll_idxs):\n",
    "        for _ in range(max_sen_len - len(sent)):\n",
    "            syll_idxs[i].append([pad_idx] * max_word_len)\n",
    "    return torch.LongTensor(syll_idxs)\n",
    "\n",
    "syl_tensor = word2syll_idxs(qw_idxs, word_idx2syll_idx)\n",
    "syl_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 29, 6])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syl_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by length and pack sequence for RNN\n",
    "lengths, sort_idx = q_len.sort(0, descending=True)\n",
    "x = syl_tensor[sort_idx]     # (batch_size, seq_len, input_size)\n",
    "        \n",
    "x = pack_padded_sequence(x, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 1,  0,  0,  0,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 1,  0,  0,  0,  0,  0],\n",
       "        [10, 11, 12,  0,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0,  0]]), batch_sizes=tensor([64, 64, 64, 64, 64, 64, 62, 58, 54, 48, 41, 34, 29, 20, 15, 12,  8,  6,\n",
       "         4,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 1,  0,  0,  0,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 1,  0,  0,  0,  0,  0],\n",
       "        [10, 11, 12,  0,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0,  0]]), batch_sizes=tensor([64, 64, 64, 64, 64, 64, 62, 58, 54, 48, 41, 34, 29, 20, 15, 12,  8,  6,\n",
       "         4,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 29, 6])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, _ = pad_packed_sequence(x, batch_first=True, total_length=29)\n",
    "_, unsort_idx = sort_idx.sort(0)\n",
    "x = x[unsort_idx]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    0,    0,    0,    0,    0],\n",
       "        [  71,    0,    0,    0,    0,    0],\n",
       "        [2200,    0,    0,    0,    0,    0],\n",
       "        [  56,    0,    0,    0,    0,    0],\n",
       "        [ 152,  190,   25,    0,    0,    0],\n",
       "        [   4,    0,    0,    0,    0,    0],\n",
       "        [   1, 2465,    0,    0,    0,    0],\n",
       "        [   1,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    0,    0,    0,    0,    0],\n",
       "        [  71,    0,    0,    0,    0,    0],\n",
       "        [2200,    0,    0,    0,    0,    0],\n",
       "        [  56,    0,    0,    0,    0,    0],\n",
       "        [ 152,  190,   25,    0,    0,    0],\n",
       "        [   4,    0,    0,    0,    0,    0],\n",
       "        [   1, 2465,    0,    0,    0,    0],\n",
       "        [   1,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syl_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/word2idx.json') as json_file:  \n",
    "    word2idx = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2syll = {val : key for key, val in syll2idx.items()}\n",
    "idx2word = {val : key for key, val in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2200, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idx2syll_idx['534']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = qw_idxs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'type'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[534]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--OOV--',\n",
       " 'What',\n",
       " 'type',\n",
       " 'of',\n",
       " 'area',\n",
       " 'is',\n",
       " 'Sichuan',\n",
       " '?',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--',\n",
       " '--NULL--']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx2word[i] for i in sent.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[71, 0, 0, 0, 0, 0],\n",
       " [2200, 0, 0, 0, 0, 0],\n",
       " [56, 0, 0, 0, 0, 0],\n",
       " [152, 190, 25, 0, 0, 0],\n",
       " [4, 0, 0, 0, 0, 0],\n",
       " [1, 2465, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syll_idxs = [word_idx2syll_idx[str(i)] for i in sent.tolist() if str(i) in word_idx2syll_idx]\n",
    "# syll_idxs = list(itertools.chain.from_iterable(syll_idxs))\n",
    "syll_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['waht', '--NULL--', '--NULL--', '--NULL--', '--NULL--', '--NULL--'],\n",
       " ['tayp', '--NULL--', '--NULL--', '--NULL--', '--NULL--', '--NULL--'],\n",
       " ['ahv', '--NULL--', '--NULL--', '--NULL--', '--NULL--', '--NULL--'],\n",
       " ['eh', 'riy', 'ah', '--NULL--', '--NULL--', '--NULL--'],\n",
       " ['ihz', '--NULL--', '--NULL--', '--NULL--', '--NULL--', '--NULL--'],\n",
       " ['--OOV--', 'waan', '--NULL--', '--NULL--', '--NULL--', '--NULL--']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[idx2syll[syll_idx] for syll_idx in word_idx2syll_idx[str(i)]] for i in sent.tolist() if str(i) in word_idx2syll_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_idxs = []\n",
    "for sent in qw_idxs:\n",
    "    syll_idxs = [word_idx2syll_idx[str(i)] for i in sent.tolist() if str(i) in word_idx2syll_idx]\n",
    "#     syll_idxs = list(itertools.chain.from_iterable(syll_idxs))\n",
    "    qs_idxs.append(syll_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(len(idxs) for idxs in qs_idxs)\n",
    "max_len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
